


<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torch.fx &mdash; PyTorch master documentation</title>
  

  
  
  
  
    <link rel="canonical" href="https://pytorch.org/docs/stable/fx.html"/>
  

  

  
  
    

  

  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <!-- <link rel="stylesheet" href="_static/pygments.css" type="text/css" /> -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.10.0-beta/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/css/jit.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torch.hub" href="hub.html" />
    <link rel="prev" title="torch.futures" href="futures.html" /> 

  
  <script src="_static/js/modernizr.min.js"></script>

  <!-- Preload the theme fonts -->

<link rel="preload" href="_static/fonts/FreightSans/freight-sans-book.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-Medium.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/FreightSans/freight-sans-medium-italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="_static/fonts/IBMPlexMono/IBMPlexMono-SemiBold.woff2" as="font" type="font/woff2" crossorigin="anonymous">

<!-- Preload the katex fonts -->

<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Math-Italic.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Main-Bold.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size1-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size4-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size2-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Size3-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
<link rel="preload" href="https://cdn.jsdelivr.net/npm/katex@0.10.0/dist/fonts/KaTeX_Caligraphic-Regular.woff2" as="font" type="font/woff2" crossorigin="anonymous">
</head>

<div class="container-fluid header-holder tutorials-header" id="header-holder">
  <div class="container">
    <div class="header-container">
      <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>

      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="active">
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-orange-arrow">
                Docs
              </a>
              <div class="resources-dropdown-menu">
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/index.html">
                  <span class="dropdown-title">PyTorch</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/audio/stable/index.html">
                  <span class="dropdown-title">torchaudio</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/text/stable/index.html">
                  <span class="dropdown-title">torchtext</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/docs/stable/torchvision/">
                  <span class="dropdown-title">torchvision</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/elastic/">
                  <span class="dropdown-title">TorchElastic</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/serve/">
                  <span class="dropdown-title">TorchServe</span>
                  <p></p>
                </a>
                <a class="doc-dropdown-option nav-dropdown-item" href="https://pytorch.org/xla">
                  <span class="dropdown-title">PyTorch on XLA Devices</span>
                  <p></p>
                </a>
            </div>
          </li>

          <li>
            <div id="resourcesDropdownButton" data-toggle="resources-dropdown" class="resources-dropdown">
              <a class="resource-option with-down-arrow">
                Resources
              </a>
              <div class="resources-dropdown-menu">
                <a class="nav-dropdown-item" href="https://pytorch.org/features">
                  <span class="dropdown-title">About</span>
                  <p>Learn about PyTorch’s features and capabilities</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/#community-module">
                  <span class="dropdown-title">Community</span>
                  <p>Join the PyTorch developer community to contribute, learn, and get your questions answered.</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/resources">
                  <span class="dropdown-title">Developer Resources</span>
                  <p>Find resources and get questions answered</p>
                </a>
                <a class="nav-dropdown-item" href="https://discuss.pytorch.org/" target="_blank">
                  <span class="dropdown-title">Forums</span>
                  <p>A place to discuss PyTorch code, issues, install, research</p>
                </a>
                <a class="nav-dropdown-item" href="https://pytorch.org/hub">
                  <span class="dropdown-title">Models (Beta)</span>
                  <p>Discover, publish, and reuse pre-trained models</p>
                </a>
              </div>
            </div>
          </li>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>

      <a class="main-menu-open-button" href="#" data-behavior="open-mobile-menu"></a>
    </div>
  </div>
</div>

<body class="pytorch-body">

   

    

    <div class="table-of-contents-link-wrapper">
      <span>Table of Contents</span>
      <a href="#" class="toggle-table-of-contents" data-behavior="toggle-table-of-contents"></a>
    </div>

    <nav data-toggle="wy-nav-shift" class="pytorch-left-menu" id="pytorch-left-menu">
      <div class="pytorch-side-scroll">
        <div class="pytorch-menu pytorch-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          <div class="pytorch-left-menu-search">
            

            
              
              
                <div class="version">
                  master (1.8.0a0+4d61109 )
                </div>
              
            

            


  


<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search Docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

            
          </div>

          
<div>
  <a style="color:#F05732" href="https://pytorch.org/docs/stable/fx.html">
    You are viewing unstable developer preview docs.
    Click here to view docs for latest stable release.
  </a>
</div>

            
            
              
            
            
              <p class="caption"><span class="caption-text">Notes</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="notes/amp_examples.html">Automatic Mixed Precision examples</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/autograd.html">Autograd mechanics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/broadcasting.html">Broadcasting semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cpu_threading_torchscript_inference.html">CPU threading and TorchScript inference</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/cuda.html">CUDA semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/ddp.html">Distributed Data Parallel</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/extending.html">Extending PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/faq.html">Frequently Asked Questions</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/large_scale_deployments.html">Features for large-scale deployments</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/modules.html">Modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/multiprocessing.html">Multiprocessing best practices</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/randomness.html">Reproducibility</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/serialization.html">Serialization semantics</a></li>
<li class="toctree-l1"><a class="reference internal" href="notes/windows.html">Windows FAQ</a></li>
</ul>
<p class="caption"><span class="caption-text">Language Bindings</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="cpp_index.html">C++</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/javadoc/">Javadoc</a></li>
</ul>
<p class="caption"><span class="caption-text">Python API</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="torch.html">torch</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.html">torch.nn</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.functional.html">torch.nn.functional</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensors.html">torch.Tensor</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_attributes.html">Tensor Attributes</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensor_view.html">Tensor Views</a></li>
<li class="toctree-l1"><a class="reference internal" href="autograd.html">torch.autograd</a></li>
<li class="toctree-l1"><a class="reference internal" href="cuda.html">torch.cuda</a></li>
<li class="toctree-l1"><a class="reference internal" href="amp.html">torch.cuda.amp</a></li>
<li class="toctree-l1"><a class="reference internal" href="backends.html">torch.backends</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributed.html">torch.distributed</a></li>
<li class="toctree-l1"><a class="reference internal" href="distributions.html">torch.distributions</a></li>
<li class="toctree-l1"><a class="reference internal" href="fft.html">torch.fft</a></li>
<li class="toctree-l1"><a class="reference internal" href="futures.html">torch.futures</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">torch.fx</a></li>
<li class="toctree-l1"><a class="reference internal" href="hub.html">torch.hub</a></li>
<li class="toctree-l1"><a class="reference internal" href="jit.html">torch.jit</a></li>
<li class="toctree-l1"><a class="reference internal" href="linalg.html">torch.linalg</a></li>
<li class="toctree-l1"><a class="reference internal" href="torch.overrides.html">torch.overrides</a></li>
<li class="toctree-l1"><a class="reference internal" href="profiler.html">torch.profiler</a></li>
<li class="toctree-l1"><a class="reference internal" href="nn.init.html">torch.nn.init</a></li>
<li class="toctree-l1"><a class="reference internal" href="onnx.html">torch.onnx</a></li>
<li class="toctree-l1"><a class="reference internal" href="optim.html">torch.optim</a></li>
<li class="toctree-l1"><a class="reference internal" href="complex_numbers.html">Complex Numbers</a></li>
<li class="toctree-l1"><a class="reference internal" href="pipeline.html">Pipeline Parallelism</a></li>
<li class="toctree-l1"><a class="reference internal" href="quantization.html">Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="rpc.html">Distributed RPC Framework</a></li>
<li class="toctree-l1"><a class="reference internal" href="random.html">torch.random</a></li>
<li class="toctree-l1"><a class="reference internal" href="sparse.html">torch.sparse</a></li>
<li class="toctree-l1"><a class="reference internal" href="storage.html">torch.Storage</a></li>
<li class="toctree-l1"><a class="reference internal" href="benchmark_utils.html">torch.utils.benchmark</a></li>
<li class="toctree-l1"><a class="reference internal" href="bottleneck.html">torch.utils.bottleneck</a></li>
<li class="toctree-l1"><a class="reference internal" href="checkpoint.html">torch.utils.checkpoint</a></li>
<li class="toctree-l1"><a class="reference internal" href="cpp_extension.html">torch.utils.cpp_extension</a></li>
<li class="toctree-l1"><a class="reference internal" href="data.html">torch.utils.data</a></li>
<li class="toctree-l1"><a class="reference internal" href="dlpack.html">torch.utils.dlpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="mobile_optimizer.html">torch.utils.mobile_optimizer</a></li>
<li class="toctree-l1"><a class="reference internal" href="model_zoo.html">torch.utils.model_zoo</a></li>
<li class="toctree-l1"><a class="reference internal" href="tensorboard.html">torch.utils.tensorboard</a></li>
<li class="toctree-l1"><a class="reference internal" href="type_info.html">Type Info</a></li>
<li class="toctree-l1"><a class="reference internal" href="named_tensor.html">Named Tensors</a></li>
<li class="toctree-l1"><a class="reference internal" href="name_inference.html">Named Tensors operator coverage</a></li>
<li class="toctree-l1"><a class="reference internal" href="__config__.html">torch.__config__</a></li>
</ul>
<p class="caption"><span class="caption-text">Libraries</span></p>
<ul>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/audio/stable">torchaudio</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/text/stable">torchtext</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/vision/stable">torchvision</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/elastic/">TorchElastic</a></li>
<li class="toctree-l1"><a class="reference external" href="https://pytorch.org/serve">TorchServe</a></li>
<li class="toctree-l1"><a class="reference external" href="http://pytorch.org/xla/">PyTorch on XLA Devices</a></li>
</ul>
<p class="caption"><span class="caption-text">Community</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="community/contribution_guide.html">PyTorch Contribution Guide</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/governance.html">PyTorch Governance</a></li>
<li class="toctree-l1"><a class="reference internal" href="community/persons_of_interest.html">PyTorch Governance | Persons of Interest</a></li>
</ul>

            
          

        </div>
      </div>
    </nav>

    <div class="pytorch-container">
      <div class="pytorch-page-level-bar" id="pytorch-page-level-bar">
        <div class="pytorch-breadcrumbs-wrapper">
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="pytorch-breadcrumbs">
    
      <li>
        <a href="index.html">
          
            Docs
          
        </a> &gt;
      </li>

        
      <li>torch.fx</li>
    
    
      <li class="pytorch-breadcrumbs-aside">
        
            
            <a href="_sources/fx.rst.txt" rel="nofollow"><img src="_static/images/view-page-source-icon.svg"></a>
          
        
      </li>
    
  </ul>

  
</div>
        </div>

        <div class="pytorch-shortcuts-wrapper" id="pytorch-shortcuts-wrapper">
          Shortcuts
        </div>
      </div>

      <section data-toggle="wy-nav-shift" id="pytorch-content-wrap" class="pytorch-content-wrap">
        <div class="pytorch-content-left">

        
          
          <div class="rst-content">
          
            <div role="main" class="main-content" itemscope="itemscope" itemtype="http://schema.org/Article">
             <article itemprop="articleBody" id="pytorch-article" class="pytorch-article">
              
  <div class="section" id="torch-fx">
<h1>torch.fx<a class="headerlink" href="#torch-fx" title="Permalink to this headline">¶</a></h1>
<div class="section" id="module-torch.fx">
<span id="overview"></span><h2>Overview<a class="headerlink" href="#module-torch.fx" title="Permalink to this headline">¶</a></h2>
<p><strong>This feature is under a Beta release and its API may change.</strong></p>
<p>FX is a toolkit for developers to use to transform <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code>
instances. FX consists of three main components: a <strong>symbolic tracer,</strong>
an <strong>intermediate representation</strong>, and <strong>Python code generation</strong>. A
demonstration of these components in action:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="c1"># Simple module for demonstration</span>
<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">param</span><span class="p">)</span><span class="o">.</span><span class="n">clamp</span><span class="p">(</span><span class="nb">min</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="nb">max</span><span class="o">=</span><span class="mf">1.0</span><span class="p">)</span>

<span class="n">module</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>

<span class="kn">from</span> <span class="nn">torch.fx</span> <span class="kn">import</span> <span class="n">symbolic_trace</span>
<span class="c1"># Symbolic tracing frontend - captures the semantics of the module</span>
<span class="n">symbolic_traced</span> <span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span> <span class="o">=</span> <span class="n">symbolic_trace</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>

<span class="c1"># High-level intermediate representation (IR) - Graph representation</span>
<span class="nb">print</span><span class="p">(</span><span class="n">symbolic_traced</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">graph(x):</span>
<span class="sd">    %param : [#users=1] = self.param</span>
<span class="sd">    %add_1 : [#users=1] = call_function[target=&lt;built-in function add&gt;](args = (%x, %param), kwargs = {})</span>
<span class="sd">    %linear_1 : [#users=1] = call_module[target=linear](args = (%add_1,), kwargs = {})</span>
<span class="sd">    %clamp_1 : [#users=1] = call_method[target=clamp](args = (%linear_1,), kwargs = {min: 0.0, max: 1.0})</span>
<span class="sd">    return clamp_1</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="c1"># Code generation - valid Python code</span>
<span class="nb">print</span><span class="p">(</span><span class="n">symbolic_traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    param = self.param</span>
<span class="sd">    add_1 = x + param;  x = param = None</span>
<span class="sd">    linear_1 = self.linear(add_1);  add_1 = None</span>
<span class="sd">    clamp_1 = linear_1.clamp(min = 0.0, max = 1.0);  linear_1 = None</span>
<span class="sd">    return clamp_1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The <strong>symbolic tracer</strong> performs “abstract interpretation” of the Python
code. It feeds fake values, called Proxies, through the code. Operations
on theses Proxies are recorded. More information about symbolic tracing
can be found in the
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.symbolic_trace">symbolic_trace</a>
and <a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Tracer">Tracer</a>
documentation.</p>
<p>The <strong>intermediate representation</strong> is the container for the operations
that were recorded during symbolic tracing. It consists of a list of
Nodes that represent function inputs, callsites (to functions, methods,
or <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> instances), and return values. More information about
the IR can be found in the documentation for
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Graph">Graph</a>. The
IR is the format on which transformations are applied.</p>
<p><strong>Python code generation</strong> is what makes FX a Python-to-Python (or
Module-to-Module) transformation toolkit. For each Graph IR, we can
create valid Python code matching the Graph’s semantics. This
functionality is wrapped up in
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.GraphModule">GraphModule</a>,
which is an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> instance that holds a <code class="docutils literal notranslate"><span class="pre">Graph</span></code> as well as a
<code class="docutils literal notranslate"><span class="pre">forward</span></code> method generated from the Graph.</p>
<p>Taken together, this pipeline of components (symbolic tracing →
intermediate representation → transforms → Python code generation)
constitutes the Python-to-Python transformation pipeline of FX.</p>
</div>
<div class="section" id="writing-transformations">
<h2>Writing Transformations<a class="headerlink" href="#writing-transformations" title="Permalink to this headline">¶</a></h2>
<p>TODO</p>
</div>
<div class="section" id="debugging-transformations">
<h2>Debugging Transformations<a class="headerlink" href="#debugging-transformations" title="Permalink to this headline">¶</a></h2>
<p>TODO</p>
</div>
<div class="section" id="limitations-of-symbolic-tracing">
<h2>Limitations of Symbolic Tracing<a class="headerlink" href="#limitations-of-symbolic-tracing" title="Permalink to this headline">¶</a></h2>
<p>FX uses a system of <strong>symbolic tracing</strong> (a.k.a <a class="reference external" href="https://en.wikipedia.org/wiki/Symbolic_execution">symbolic
execution</a>)
to capture the semantics of programs in a transformable/analyzable form.
The system is <strong>tracing</strong> in that it executes the program (really an
<code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> or function) to gather this information. It is
<strong>symbolic</strong> in that the data flowing through the program during this
execution is not real data, but rather symbols (“Proxy” in FX parlance).</p>
<p>Although symbolic tracing works for most neural net code, it has some
limitations.</p>
<div class="section" id="dynamic-control-flow">
<h3>Dynamic Control Flow<a class="headerlink" href="#dynamic-control-flow" title="Permalink to this headline">¶</a></h3>
<p>The main limitation of symbolic tracing is it does not currently support
<em>dynamic control flow</em>. That is, loops or <code class="docutils literal notranslate"><span class="pre">if</span></code> statements where the
condition may depend on the input values of the program.</p>
<p>For example, let’s examine the following program:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">func_to_trace</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">dim0</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">size</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">dim0</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">func_to_trace</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  &lt;...&gt;</span>
<span class="sd">  File &quot;dyn.py&quot;, line 6, in func_to_trace</span>
<span class="sd">    if dim0 == 3:</span>
<span class="sd">  File &quot;pytorch/torch/fx/proxy.py&quot;, line 155, in __bool__</span>
<span class="sd">    return self.tracer.to_bool(self)</span>
<span class="sd">  File &quot;pytorch/torch/fx/proxy.py&quot;, line 85, in to_bool</span>
<span class="sd">    raise TraceError(&#39;symbolically traced variables cannot be used as inputs to control flow&#39;)</span>
<span class="sd">torch.fx.proxy.TraceError: symbolically traced variables cannot be used as inputs to control flow</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The condition to the <code class="docutils literal notranslate"><span class="pre">if</span></code> statement relies on the value of <code class="docutils literal notranslate"><span class="pre">dim0</span></code>,
which eventually relies on the value of <code class="docutils literal notranslate"><span class="pre">x</span></code>, a function input. Since
<code class="docutils literal notranslate"><span class="pre">x</span></code> can change (i.e. if you pass a new input tensor to the traced
function), this is <em>dynamic control flow</em>. The traceback walks back up
through your code to show you where this situation happens.</p>
<div class="section" id="static-control-flow">
<h4>Static Control Flow<a class="headerlink" href="#static-control-flow" title="Permalink to this headline">¶</a></h4>
<p>On the other hand, so-called <em>static control flow</em> is supported. Static
control flow is loops or <code class="docutils literal notranslate"><span class="pre">if</span></code> statements whose value cannot change
across invocations. Typically, in PyTorch programs, this control flow
arises for code making decisions about a model’s architecture based on
hyper-parameters. As a concrete example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">do_activation</span> <span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">do_activation</span> <span class="o">=</span> <span class="n">do_activation</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">512</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># This if-statement is so-called static control flow.</span>
        <span class="c1"># Its condition does not depend on any input values</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">do_activation</span><span class="p">:</span>
            <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>

<span class="n">without_activation</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">(</span><span class="n">do_activation</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">with_activation</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">(</span><span class="n">do_activation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">traced_without_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">without_activation</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced_without_activation</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    linear_1 = self.linear(x);  x = None</span>
<span class="sd">    return linear_1</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="n">traced_with_activation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">with_activation</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced_with_activation</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">import torch</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    linear_1 = self.linear(x);  x = None</span>
<span class="sd">    relu_1 = torch.relu(linear_1);  linear_1 = None</span>
<span class="sd">    return relu_1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The if-statement <code class="docutils literal notranslate"><span class="pre">if</span> <span class="pre">self.do_activation</span></code> does not depend on any
function inputs, thus it is static. <code class="docutils literal notranslate"><span class="pre">do_activation</span></code> can be considered
to be a hyper-parameter, and the traces of different instances of
<code class="docutils literal notranslate"><span class="pre">MyModule</span></code> with different values for that parameter have different
code. This is a valid pattern that is supported by symbolic tracing.</p>
<p>Many instances of dynamic control flow are semantically static control
flow. These instances can be made to support symbolic tracing by
removing the data dependencies on input values, for example by moving
values to <code class="docutils literal notranslate"><span class="pre">Module</span></code> attributes or by passing constant values during
symbolic tracing:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flag</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">flag</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span>
    <span class="k">else</span><span class="p">:</span> <span class="k">return</span> <span class="n">x</span><span class="o">*</span><span class="mi">2</span>

<span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">f</span><span class="p">)</span> <span class="c1"># Fails!</span>

<span class="k">def</span> <span class="nf">g</span><span class="p">(</span><span class="n">flag</span><span class="p">):</span>
    <span class="k">return</span> <span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">f</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">flag</span><span class="p">)</span>

<span class="n">new_f</span> <span class="o">=</span> <span class="n">g</span><span class="p">(</span><span class="n">flag</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">new_f</span><span class="p">)</span>
</pre></div>
</div>
<p>In the case of truly dynamic control flow, the sections of the program
that contain this code can be traced as calls to the Method (see
<a class="reference internal" href="#customizing-tracing"><span class="std std-ref">Customizing Tracing with the Tracer class</span></a>) or function (see
<a class="reference internal" href="#torch.fx.wrap" title="torch.fx.wrap"><code class="xref py py-func docutils literal notranslate"><span class="pre">wrap()</span></code></a>) rather than tracing through them.</p>
</div>
</div>
<div class="section" id="non-torch-functions">
<h3>Non-<code class="docutils literal notranslate"><span class="pre">torch</span></code> Functions<a class="headerlink" href="#non-torch-functions" title="Permalink to this headline">¶</a></h3>
<p>FX uses <code class="docutils literal notranslate"><span class="pre">__torch_function__</span></code> as the mechanism by which it intercepts
calls (see the <a class="reference external" href="https://github.com/pytorch/pytorch/blob/master/torch/fx/OVERVIEW.md#technical-details">technical
overview</a>
for more information about this). Some functions, such as builtin Python
functions or those in the <code class="docutils literal notranslate"><span class="pre">math</span></code> module, are things that are not
covered by <code class="docutils literal notranslate"><span class="pre">__torch_function__</span></code>, but we would still like to capture
them in symbolic tracing. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">sqrt</span>

<span class="k">def</span> <span class="nf">normalize</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Normalize `x` by the size of the batch dimension</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">/</span> <span class="n">sqrt</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="c1"># It&#39;s valid Python code</span>
<span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  &lt;...&gt;</span>
<span class="sd">  File &quot;sqrt.py&quot;, line 9, in normalize</span>
<span class="sd">    return x / sqrt(len(x))</span>
<span class="sd">  File &quot;pytorch/torch/fx/proxy.py&quot;, line 161, in __len__</span>
<span class="sd">    raise RuntimeError(&quot;&#39;len&#39; is not supported in symbolic tracing by default. If you want &quot;</span>
<span class="sd">RuntimeError: &#39;len&#39; is not supported in symbolic tracing by default. If you want this call to be recorded, please call torch.fx.wrap(&#39;len&#39;) at module scope</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The error tells us that the built-in function <code class="docutils literal notranslate"><span class="pre">len</span></code> is not supported.
We can make it so that functions like this are recorded in the trace as
direct calls using the <a class="reference internal" href="#torch.fx.wrap" title="torch.fx.wrap"><code class="xref py py-func docutils literal notranslate"><span class="pre">wrap()</span></code></a> API:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">&#39;len&#39;</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">&#39;sqrt&#39;</span><span class="p">)</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">normalize</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">import math</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    len_1 = len(x)</span>
<span class="sd">    sqrt_1 = math.sqrt(len_1);  len_1 = None</span>
<span class="sd">    truediv = x / sqrt_1;  x = sqrt_1 = None</span>
<span class="sd">    return truediv</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
</div>
<div class="section" id="customizing-tracing-with-the-tracer-class">
<span id="customizing-tracing"></span><h3>Customizing Tracing with the <code class="docutils literal notranslate"><span class="pre">Tracer</span></code> class<a class="headerlink" href="#customizing-tracing-with-the-tracer-class" title="Permalink to this headline">¶</a></h3>
<p>The <a class="reference internal" href="#torch.fx.Tracer" title="torch.fx.Tracer"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tracer</span></code></a> class is the class that underlies the
implementation of <code class="docutils literal notranslate"><span class="pre">symbolic_trace</span></code>. The behavior of tracing can be
customized by subclassing Tracer, like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyCustomTracer</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Tracer</span><span class="p">):</span>
    <span class="c1"># Inside here you can override various methods</span>
    <span class="c1"># to customize tracing. See the `Tracer` API</span>
    <span class="c1"># reference</span>
    <span class="k">pass</span>


<span class="c1"># Let&#39;s use this custom tracer to trace through this module</span>
<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>

<span class="n">mod</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>

<span class="n">traced_graph</span> <span class="o">=</span> <span class="n">MyCustomTracer</span><span class="p">()</span><span class="o">.</span><span class="n">trace</span><span class="p">(</span><span class="n">mod</span><span class="p">)</span>
<span class="c1"># trace() returns a Graph. Let&#39;s wrap it up in a</span>
<span class="c1"># GraphModule to make it runnable</span>
<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">GraphModule</span><span class="p">(</span><span class="n">mod</span><span class="p">,</span> <span class="n">traced_graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="section" id="leaf-modules">
<h4>Leaf Modules<a class="headerlink" href="#leaf-modules" title="Permalink to this headline">¶</a></h4>
<p>Leaf Modules are the modules that appear as calls in the symbolic trace
rather than being traced through. The default set of leaf modules is the
set of standard <code class="docutils literal notranslate"><span class="pre">torch.nn</span></code> module instances. For example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MySpecialSubmodule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">submod</span> <span class="o">=</span> <span class="n">MySpecialSubmodule</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">submod</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>

<span class="n">traced</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">MyModule</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">traced</span><span class="o">.</span><span class="n">code</span><span class="p">)</span>
<span class="c1"># `linear` is preserved as a call, yet `submod` is traced though.</span>
<span class="c1"># This is because the default set of &quot;Leaf Modules&quot; includes all</span>
<span class="c1"># standard `torch.nn` modules.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">import torch</span>
<span class="sd">def forward(self, x):</span>
<span class="sd">    linear_1 = self.linear(x);  x = None</span>
<span class="sd">    neg_1 = torch.neg(linear_1);  linear_1 = None</span>
<span class="sd">    return neg_1</span>
<span class="sd">&quot;&quot;&quot;</span>
</pre></div>
</div>
<p>The set of leaf modules can be customized by overriding
<a class="reference internal" href="#torch.fx.Tracer.is_leaf_module" title="torch.fx.Tracer.is_leaf_module"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Tracer.is_leaf_module()</span></code></a>.</p>
</div>
</div>
<div class="section" id="miscellanea">
<h3>Miscellanea<a class="headerlink" href="#miscellanea" title="Permalink to this headline">¶</a></h3>
<ul class="simple">
<li><p>Tensor constructors (e.g. <code class="docutils literal notranslate"><span class="pre">torch.zeros</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.ones</span></code>,
<code class="docutils literal notranslate"><span class="pre">torch.rand</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.randn</span></code>, <code class="docutils literal notranslate"><span class="pre">torch.sparse_coo_tensor</span></code>)
are currently not traceable.</p>
<ul>
<li><p>The deterministic constructors (<code class="docutils literal notranslate"><span class="pre">zeros</span></code>, <code class="docutils literal notranslate"><span class="pre">ones</span></code>) can be used
and the value they produce will be embedded in the trace as a
constant. This is only problematic if the arguments to these
constructors refers to dynamic input sizes. In this case,
<code class="docutils literal notranslate"><span class="pre">ones_like</span></code> or <code class="docutils literal notranslate"><span class="pre">zeros_like</span></code> may be a viable substitute.</p></li>
<li><p>Nondeterministic constructors (<code class="docutils literal notranslate"><span class="pre">rand</span></code>, <code class="docutils literal notranslate"><span class="pre">randn</span></code>) will have a
single random value embedded in the trace. This is likely not the
intended behavior.</p></li>
<li><p>This behavior may be fixed in a future release.</p></li>
</ul>
</li>
<li><p>Type annotations</p>
<ul>
<li><p>Python 3-style type annotations (e.g.
<code class="docutils literal notranslate"><span class="pre">func(x</span> <span class="pre">:</span> <span class="pre">torch.Tensor,</span> <span class="pre">y</span> <span class="pre">:</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">torch.Tensor</span></code>) are supported
and will be preserved by symbolic tracing.</p></li>
<li><p>Python 2-style comment type annotations
<code class="docutils literal notranslate"><span class="pre">#</span> <span class="pre">type:</span> <span class="pre">(torch.Tensor,</span> <span class="pre">int)</span> <span class="pre">-&gt;</span> <span class="pre">torch.Tensor</span></code> are not currently
supported.</p></li>
<li><p>Annotations on local names within a function are not currently
supported.</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="api-reference">
<h2>API Reference<a class="headerlink" href="#api-reference" title="Permalink to this headline">¶</a></h2>
<dl class="py function">
<dt id="torch.fx.symbolic_trace">
<code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">symbolic_trace</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#symbolic_trace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.symbolic_trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Symbolic tracing API</p>
<p>Given an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> or function instance <code class="docutils literal notranslate"><span class="pre">root</span></code>, this function will return a <code class="docutils literal notranslate"><span class="pre">GraphModule</span></code>
constructed by recording operations seen while tracing through <code class="docutils literal notranslate"><span class="pre">root</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>root</strong> (<em>Union</em><em>[</em><a class="reference internal" href="generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><em>torch.nn.Module</em></a><em>, </em><em>Callable</em><em>]</em>) – Module or function to be traced and converted
into a Graph representation.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>a Module created from the recorded operations from <code class="docutils literal notranslate"><span class="pre">root</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p><a class="reference internal" href="#torch.fx.GraphModule" title="torch.fx.GraphModule">GraphModule</a></p>
</dd>
</dl>
</dd></dl>

<dl class="py function">
<dt id="torch.fx.wrap">
<code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">wrap</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">fn_or_name</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#wrap"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.wrap" title="Permalink to this definition">¶</a></dt>
<dd><p>This function can be called at module-level scope to register fn_or_name as a “leaf function”.
A “leaf function” will be preserved as a CallFunction node in the FX trace instead of being
traced through:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># foo/bar/baz.py</span>
<span class="k">def</span> <span class="nf">my_custom_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span>

<span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span><span class="p">(</span><span class="s1">&#39;my_custom_function&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fn_to_be_traced</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="c1"># When symbolic tracing, the below call to my_custom_function will be inserted into</span>
    <span class="c1"># the graph rather than tracing it.</span>
    <span class="k">return</span> <span class="n">my_custom_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
<p>This function can also equivalently be used as a decorator:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># foo/bar/baz.py</span>
<span class="nd">@torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">wrap</span>
<span class="k">def</span> <span class="nf">my_custom_function</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">x</span> <span class="o">*</span> <span class="n">x</span> <span class="o">+</span> <span class="n">y</span> <span class="o">*</span> <span class="n">y</span>
</pre></div>
</div>
<p>A wrapped function can be thought of a “leaf function”, analogous to the concept of
“leaf modules”, that is, they are functions that are left as calls in the FX trace
rather than traced through.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>fn_or_name</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>Callable</em><em>]</em>) – The function or name of the global function to insert into the
graph when it’s called</p>
</dd>
</dl>
</dd></dl>

<dl class="py class">
<dt id="torch.fx.GraphModule">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">GraphModule</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="o">**</span><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.GraphModule" title="Permalink to this definition">¶</a></dt>
<dd><p>GraphModule is an nn.Module generated from an fx.Graph. Graphmodule has a
<code class="docutils literal notranslate"><span class="pre">graph</span></code> attribute, as well as <code class="docutils literal notranslate"><span class="pre">code</span></code> and <code class="docutils literal notranslate"><span class="pre">forward</span></code> attributes generated
from that <code class="docutils literal notranslate"><span class="pre">graph</span></code>.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>When <code class="docutils literal notranslate"><span class="pre">graph</span></code> is reassigned, <code class="docutils literal notranslate"><span class="pre">code</span></code> and <code class="docutils literal notranslate"><span class="pre">forward</span></code> will be automatically
regenerated. However, if you edit the contents of the <code class="docutils literal notranslate"><span class="pre">graph</span></code> without reassigning
the <code class="docutils literal notranslate"><span class="pre">graph</span></code> attribute itself, you must call <code class="docutils literal notranslate"><span class="pre">recompile()</span></code> to update the generated
code.</p>
</div>
<dl class="py method">
<dt id="torch.fx.GraphModule.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root</span></em>, <em class="sig-param"><span class="n">graph</span></em>, <em class="sig-param"><span class="n">class_name</span><span class="o">=</span><span class="default_value">'GraphModule'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.GraphModule.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct a GraphModule.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>root</strong> (<em>Union</em><em>[</em><a class="reference internal" href="generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><em>torch.nn.Module</em></a><em>, </em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>Any</em><em>]</em>) – <code class="docutils literal notranslate"><span class="pre">root</span></code> can either be an nn.Module instance or a Dict mapping strings to any attribute type.
In the case that <code class="docutils literal notranslate"><span class="pre">root</span></code> is a Module, any references to Module-based objects (via qualified
name) in the Graph’s Nodes’ <code class="docutils literal notranslate"><span class="pre">target</span></code> field will be copied over from the respective place
within <code class="docutils literal notranslate"><span class="pre">root</span></code>’s Module hierarchy into the GraphModule’s module hierarchy.
In the case that <code class="docutils literal notranslate"><span class="pre">root</span></code> is a dict, the qualified name found in a Node’s <code class="docutils literal notranslate"><span class="pre">target</span></code> will be
looked up directly in the dict’s keys. The object mapped to by the Dict will be copied
over into the appropriate place within the GraphModule’s module hierarchy.</p></li>
<li><p><strong>graph</strong> (<a class="reference internal" href="#torch.fx.Graph" title="torch.fx.Graph"><em>Graph</em></a>) – <code class="docutils literal notranslate"><span class="pre">graph</span></code> contains the nodes this GraphModule should use for code generation</p></li>
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – <code class="docutils literal notranslate"><span class="pre">name</span></code> denotes the name of this GraphModule for debugging purposes. If it’s unset, all
error messages will report as originating from <code class="docutils literal notranslate"><span class="pre">GraphModule</span></code>. It may be helpful to set this
to <code class="docutils literal notranslate"><span class="pre">root</span></code>’s original name or a name that makes sense within the context of your transform.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.GraphModule.code">
<em class="property">property </em><code class="sig-name descname">code</code><a class="headerlink" href="#torch.fx.GraphModule.code" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the Python code generated from the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> underlying this
<code class="docutils literal notranslate"><span class="pre">GraphModule</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.GraphModule.graph">
<em class="property">property </em><code class="sig-name descname">graph</code><a class="headerlink" href="#torch.fx.GraphModule.graph" title="Permalink to this definition">¶</a></dt>
<dd><p>Return the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> underlying this <code class="docutils literal notranslate"><span class="pre">GraphModule</span></code></p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.GraphModule.recompile">
<code class="sig-name descname">recompile</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.recompile"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.GraphModule.recompile" title="Permalink to this definition">¶</a></dt>
<dd><p>Recompile this GraphModule from its <code class="docutils literal notranslate"><span class="pre">graph</span></code> attribute. This should be
called after editing the contained <code class="docutils literal notranslate"><span class="pre">graph</span></code>, otherwise the generated
code of this <code class="docutils literal notranslate"><span class="pre">GraphModule</span></code> will be out of date.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.GraphModule.to_folder">
<code class="sig-name descname">to_folder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">folder</span></em>, <em class="sig-param"><span class="n">module_name</span><span class="o">=</span><span class="default_value">'FxModule'</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph_module.html#GraphModule.to_folder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.GraphModule.to_folder" title="Permalink to this definition">¶</a></dt>
<dd><p>Dumps out module to <code class="docutils literal notranslate"><span class="pre">folder</span></code> with <code class="docutils literal notranslate"><span class="pre">module_name</span></code> so that it can be
imported with <code class="docutils literal notranslate"><span class="pre">from</span> <span class="pre">&lt;folder&gt;</span> <span class="pre">import</span> <span class="pre">&lt;module_name&gt;</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>folder</strong> (<em>Union</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><a class="reference external" href="https://docs.python.org/3/library/os.html#os.PathLike" title="(in Python v3.9)"><em>os.PathLike</em></a><em>]</em>) – The folder to write the code out to</p></li>
<li><p><strong>module_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – Top-level name to use for the <code class="docutils literal notranslate"><span class="pre">Module</span></code> while
writing out the code</p></li>
</ul>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.fx.Graph">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">Graph</code><a class="reference internal" href="_modules/torch/fx/graph.html#Graph"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">Graph</span></code> is the main data structure used in the FX Intermediate Representation.
It consists of a series of <code class="docutils literal notranslate"><span class="pre">Node</span></code> s, each representing callsites (or other
syntactic constructs). The list of <code class="docutils literal notranslate"><span class="pre">Node</span></code> s, taken together, constitute a
valid Python function.</p>
<p>For example, the following code</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.fx</span>

<span class="k">class</span> <span class="nc">MyModule</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">param</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">linear</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">5</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">topk</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="p">(</span><span class="n">x</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">linear</span><span class="o">.</span><span class="n">weight</span><span class="p">)</span><span class="o">.</span><span class="n">relu</span><span class="p">(),</span> <span class="n">dim</span><span class="o">=-</span><span class="mi">1</span><span class="p">),</span> <span class="mi">3</span><span class="p">)</span>

<span class="n">m</span> <span class="o">=</span> <span class="n">MyModule</span><span class="p">()</span>
<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">m</span><span class="p">)</span>
</pre></div>
</div>
<p>Will produce the following Graph:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">gm</span><span class="o">.</span><span class="n">graph</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-text notranslate"><div class="highlight"><pre><span></span>graph(x):
    %linear_weight : [#users=1] = self.linear.weight
    %add_1 : [#users=1] = call_function[target=operator.add](args = (%x, %linear_weight), kwargs = {})
    %linear_1 : [#users=1] = call_module[target=linear](args = (%add_1,), kwargs = {})
    %relu_1 : [#users=1] = call_method[target=relu](args = (%linear_1,), kwargs = {})
    %sum_1 : [#users=1] = call_function[target=torch.sum](args = (%relu_1,), kwargs = {dim: -1})
    %topk_1 : [#users=1] = call_function[target=torch.topk](args = (%sum_1, 3), kwargs = {})
    return topk_1
</pre></div>
</div>
<p>For the semantics of operations represented in the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>, please see <a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a>.</p>
<dl class="py method">
<dt id="torch.fx.Graph.__init__">
<code class="sig-name descname">__init__</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.__init__"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.__init__" title="Permalink to this definition">¶</a></dt>
<dd><p>Construct an empty Graph.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.call_function">
<code class="sig-name descname">call_function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">the_function</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">kwargs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.call_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.call_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert a <code class="docutils literal notranslate"><span class="pre">call_function</span></code> <code class="docutils literal notranslate"><span class="pre">Node</span></code> into the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. A <code class="docutils literal notranslate"><span class="pre">call_function</span></code> node
represents a call to a Python callable, specified by <code class="docutils literal notranslate"><span class="pre">the_function</span></code>. <code class="docutils literal notranslate"><span class="pre">the_function</span></code>
can be</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>the_function</strong> (<em>Callable</em><em>[</em><em>..</em><em>, </em><em>Any</em><em>]</em>) – The function to be called. Can be any PyTorch
operator, Python function, or member of the <code class="docutils literal notranslate"><span class="pre">builtins</span></code> or <code class="docutils literal notranslate"><span class="pre">operator</span></code>
namespaces.</p></li>
<li><p><strong>args</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>Argument</em><em>, </em><em>..</em><em>]</em><em>]</em>) – The positional arguments to be passed
to the called function.</p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>Argument</em><em>]</em><em>]</em>) – The keyword arguments to be passed
to the called function</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have.</p></li>
</ul>
</dd>
</dl>
<p>Returns</p>
<blockquote>
<div><p>The newly created and inserted <code class="docutils literal notranslate"><span class="pre">call_function</span></code> node.</p>
</div></blockquote>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same insertion point and type expression rules apply for this method
as <a class="reference internal" href="#torch.fx.Graph.create_node" title="torch.fx.Graph.create_node"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Graph.create_node()</span></code></a>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.call_method">
<code class="sig-name descname">call_method</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">method_name</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">kwargs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.call_method"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.call_method" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert a <code class="docutils literal notranslate"><span class="pre">call_method</span></code> <code class="docutils literal notranslate"><span class="pre">Node</span></code> into the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. A <code class="docutils literal notranslate"><span class="pre">call_method</span></code> node
represents a call to a given method on the 0th element of <code class="docutils literal notranslate"><span class="pre">args</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>method_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The name of the method to apply to the self argument.
For example, if args[0] is a <code class="docutils literal notranslate"><span class="pre">Node</span></code> representing a <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>,
then to call <code class="docutils literal notranslate"><span class="pre">relu()</span></code> on that <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>, pass <code class="docutils literal notranslate"><span class="pre">relu</span></code> to <code class="docutils literal notranslate"><span class="pre">method_name</span></code>.</p></li>
<li><p><strong>args</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>Argument</em><em>, </em><em>..</em><em>]</em><em>]</em>) – The positional arguments to be passed
to the called method. Note that this <em>should</em> include a <code class="docutils literal notranslate"><span class="pre">self</span></code> argument.</p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>Argument</em><em>]</em><em>]</em>) – The keyword arguments to be passed
to the called method</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The newly created and inserted <code class="docutils literal notranslate"><span class="pre">call_method</span></code> node.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same insertion point and type expression rules apply for this method
as <a class="reference internal" href="#torch.fx.Graph.create_node" title="torch.fx.Graph.create_node"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Graph.create_node()</span></code></a>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.call_module">
<code class="sig-name descname">call_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module_name</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">kwargs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.call_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.call_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert a <code class="docutils literal notranslate"><span class="pre">call_module</span></code> <code class="docutils literal notranslate"><span class="pre">Node</span></code> into the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. A <code class="docutils literal notranslate"><span class="pre">call_module</span></code> node
represents a call to the forward() function of a <code class="docutils literal notranslate"><span class="pre">Module</span></code> in the <code class="docutils literal notranslate"><span class="pre">Module</span></code>
hierarchy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>module_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The qualified name of the <code class="docutils literal notranslate"><span class="pre">Module</span></code> in the <code class="docutils literal notranslate"><span class="pre">Module</span></code>
hierarchy to be called. For example, if the traced <code class="docutils literal notranslate"><span class="pre">Module</span></code> has a
submodule named <code class="docutils literal notranslate"><span class="pre">foo</span></code>, which has a submodule named <code class="docutils literal notranslate"><span class="pre">bar</span></code>, the
qualified name <code class="docutils literal notranslate"><span class="pre">foo.bar</span></code> should be passed as <code class="docutils literal notranslate"><span class="pre">module_name</span></code> to
call that module.</p></li>
<li><p><strong>args</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>Argument</em><em>, </em><em>..</em><em>]</em><em>]</em>) – The positional arguments to be passed
to the called method. Note that this should <em>not</em> include a <code class="docutils literal notranslate"><span class="pre">self</span></code> argument.</p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>Argument</em><em>]</em><em>]</em>) – The keyword arguments to be passed
to the called method</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The newly-created and inserted <code class="docutils literal notranslate"><span class="pre">call_module</span></code> node.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same insertion point and type expression rules apply for this method
as <a class="reference internal" href="#torch.fx.Graph.create_node" title="torch.fx.Graph.create_node"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Graph.create_node()</span></code></a>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.create_node">
<code class="sig-name descname">create_node</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">op</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">kwargs</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">name</span><span class="o">=</span><span class="default_value">None</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.create_node"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.create_node" title="Permalink to this definition">¶</a></dt>
<dd><p>Create a <code class="docutils literal notranslate"><span class="pre">Node</span></code> and add it to the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> at the current insert-point.
Note that the current insert-point can be set via <a class="reference internal" href="#torch.fx.Graph.inserting_before" title="torch.fx.Graph.inserting_before"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Graph.inserting_before()</span></code></a>
and <a class="reference internal" href="#torch.fx.Graph.inserting_after" title="torch.fx.Graph.inserting_after"><code class="xref py py-meth docutils literal notranslate"><span class="pre">Graph.inserting_after()</span></code></a>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>op</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – the opcode for this Node. One of ‘call_function’, ‘call_method’, ‘get_attr’,
‘call_module’, ‘placeholder’, or ‘output’. The semantics of these opcodes are
described in the <code class="docutils literal notranslate"><span class="pre">Graph</span></code> docstring.</p></li>
<li><p><strong>args</strong> (<em>Optional</em><em>[</em><em>Tuple</em><em>[</em><em>Argument</em><em>, </em><em>..</em><em>]</em><em>]</em>) – is a tuple of arguments to this node.</p></li>
<li><p><strong>kwargs</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>, </em><em>Argument</em><em>]</em><em>]</em>) – the kwargs of this Node</p></li>
<li><p><strong>name</strong> (<em>Optional</em><em>[</em><a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a><em>]</em>) – an optional string name for the <code class="docutils literal notranslate"><span class="pre">Node</span></code>.
This will influence the name of the value assigned to in the
Python generated code.</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The newly-created and inserted node.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.erase_node">
<code class="sig-name descname">erase_node</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">to_erase</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.erase_node"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.erase_node" title="Permalink to this definition">¶</a></dt>
<dd><p>Erases a <code class="docutils literal notranslate"><span class="pre">Node</span></code> from the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. Throws an exception if
there are still users of that node in the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>to_erase</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The <code class="docutils literal notranslate"><span class="pre">Node</span></code> to erase from the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.get_attr">
<code class="sig-name descname">get_attr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">qualified_name</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.get_attr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.get_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert a <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> node into the Graph. A <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> <code class="docutils literal notranslate"><span class="pre">Node</span></code> represents the
fetch of an attribute from the <code class="docutils literal notranslate"><span class="pre">Module</span></code> hierarchy.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>qualified_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – the fully-qualified name of the attribute to be retrieved.
For example, if the traced Module has a submodule named <code class="docutils literal notranslate"><span class="pre">foo</span></code>, which has a
submodule named <code class="docutils literal notranslate"><span class="pre">bar</span></code>, which has an attribute named <code class="docutils literal notranslate"><span class="pre">baz</span></code>, the qualified
name <code class="docutils literal notranslate"><span class="pre">foo.bar.baz</span></code> should be passed as <code class="docutils literal notranslate"><span class="pre">qualified_name</span></code>.</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The newly-created and inserted <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> node.</p>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same insertion point and type expression rules apply for this method
as <code class="docutils literal notranslate"><span class="pre">Graph.create_node</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.graph_copy">
<code class="sig-name descname">graph_copy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">g</span></em>, <em class="sig-param"><span class="n">val_map</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.graph_copy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.graph_copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy all nodes from a given graph into <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>g</strong> (<a class="reference internal" href="#torch.fx.Graph" title="torch.fx.Graph"><em>Graph</em></a>) – The source graph from which to copy Nodes.</p></li>
<li><p><strong>val_map</strong> (<em>Dict</em><em>[</em><a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a><em>, </em><a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a><em>]</em>) – a dictionary that will be populated with a mapping
from nodes in <code class="docutils literal notranslate"><span class="pre">g</span></code> to nodes in <code class="docutils literal notranslate"><span class="pre">self</span></code>. Note that <code class="docutils literal notranslate"><span class="pre">val_map</span></code> can be passed
in with values in it already to override copying of certain values.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The value in <code class="docutils literal notranslate"><span class="pre">self</span></code> that is now equivalent to the output value in <code class="docutils literal notranslate"><span class="pre">g</span></code>,
if <code class="docutils literal notranslate"><span class="pre">g</span></code> had an <code class="docutils literal notranslate"><span class="pre">output</span></code> node. <code class="docutils literal notranslate"><span class="pre">None</span></code> otherwise.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.inserting_after">
<code class="sig-name descname">inserting_after</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.inserting_after"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.inserting_after" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the point at which create_node and companion methods will insert into the graph.
When used within a ‘with’ statement, this will temporary set the insert point and
then restore it when the with statement exits:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">inserting_after</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="o">...</span> <span class="c1"># inserting after node n</span>
<span class="o">...</span> <span class="c1"># insert point restored to what it was previously</span>
<span class="n">g</span><span class="o">.</span><span class="n">inserting_after</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="c1">#  set the insert point permanently</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a><em>]</em>) – The node before which to insert. If None this will insert after
the beginning of the entire graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A resource manager that will restore the insert point on <code class="docutils literal notranslate"><span class="pre">__exit__</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.inserting_before">
<code class="sig-name descname">inserting_before</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.inserting_before"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.inserting_before" title="Permalink to this definition">¶</a></dt>
<dd><p>Set the point at which create_node and companion methods will insert into the graph.
When used within a ‘with’ statement, this will temporary set the insert point and
then restore it when the with statement exits:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">with</span> <span class="n">g</span><span class="o">.</span><span class="n">inserting_before</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="o">...</span> <span class="c1"># inserting before node n</span>
<span class="o">...</span> <span class="c1"># insert point restored to what it was previously</span>
<span class="n">g</span><span class="o">.</span><span class="n">inserting_before</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="c1">#  set the insert point permanently</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a><em>]</em>) – The node before which to insert. If None this will insert before
the beginning of the entire graph.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A resource manager that will restore the insert point on <code class="docutils literal notranslate"><span class="pre">__exit__</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.lint">
<code class="sig-name descname">lint</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.lint"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.lint" title="Permalink to this definition">¶</a></dt>
<dd><p>Runs various checks on this Graph to make sure it is well-formed. In
particular:
- Checks Nodes have correct ownership (owned by this graph)
- Checks Nodes appear in topological order
- If <code class="docutils literal notranslate"><span class="pre">root</span></code> is provided, checks that targets exist in <code class="docutils literal notranslate"><span class="pre">root</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>root</strong> (<em>Optional</em><em>[</em><a class="reference internal" href="generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><em>torch.nn.Module</em></a><em>]</em>) – The root module with which to check
for targets. This is equivalent to the <code class="docutils literal notranslate"><span class="pre">root</span></code> argument that is
passed when constructing a <code class="docutils literal notranslate"><span class="pre">GraphModule</span></code>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.node_copy">
<code class="sig-name descname">node_copy</code><span class="sig-paren">(</span><em class="sig-param">node</em>, <em class="sig-param">arg_transform=&lt;function Graph.&lt;lambda&gt;&gt;</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.node_copy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.node_copy" title="Permalink to this definition">¶</a></dt>
<dd><p>Copy a node from one graph into another. <code class="docutils literal notranslate"><span class="pre">arg_transform</span></code> needs to transform arguments from
the graph of node to the graph of self. Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Copying all the nodes in `g` into `new_graph`</span>
<span class="n">g</span> <span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">Graph</span> <span class="o">=</span> <span class="o">...</span>
<span class="n">new_graph</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">graph</span><span class="p">()</span>
<span class="n">value_remap</span> <span class="o">=</span> <span class="p">{}</span>
<span class="k">for</span> <span class="n">node</span> <span class="ow">in</span> <span class="n">g</span><span class="o">.</span><span class="n">nodes</span><span class="p">:</span>
    <span class="n">value_remap</span><span class="p">[</span><span class="n">node</span><span class="p">]</span> <span class="o">=</span> <span class="n">new_graph</span><span class="o">.</span><span class="n">node_copy</span><span class="p">(</span><span class="n">node</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">n</span> <span class="p">:</span> <span class="n">value_remap</span><span class="p">[</span><span class="n">n</span><span class="p">])</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>node</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The node to copy into <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></li>
<li><p><strong>arg_transform</strong> (<em>Callable</em><em>[</em><em>[</em><a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a><em>]</em><em>, </em><em>Argument</em><em>]</em>) – A function that transforms
<code class="docutils literal notranslate"><span class="pre">Node</span></code> arguments in node’s <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> into the
equivalent argument in <code class="docutils literal notranslate"><span class="pre">self</span></code>. In the simplest case, this should
retrieve a value out of a table mapping Nodes in the original
graph to <code class="docutils literal notranslate"><span class="pre">self</span></code>.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.nodes">
<em class="property">property </em><code class="sig-name descname">nodes</code><a class="headerlink" href="#torch.fx.Graph.nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>Get the list of Nodes that constitute this Graph.</p>
<p>Note that this <code class="docutils literal notranslate"><span class="pre">Node</span></code> list representation is a doubly-linked list. Mutations
during iteration (e.g. delete a Node, add a Node) are safe.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>A doubly-linked list of Nodes. Note that <code class="docutils literal notranslate"><span class="pre">reversed</span></code> can be called on
this list to switch iteration order.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">result</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert an <code class="docutils literal notranslate"><span class="pre">output</span></code> <code class="docutils literal notranslate"><span class="pre">Node</span></code> into the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. An <code class="docutils literal notranslate"><span class="pre">output</span></code> node represents
a <code class="docutils literal notranslate"><span class="pre">return</span></code> statement in Python code. <code class="docutils literal notranslate"><span class="pre">result</span></code> is the value that should
be returned.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>result</strong> (<em>Argument</em>) – The value to be returned.</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have.</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same insertion point and type expression rules apply for this method
as <code class="docutils literal notranslate"><span class="pre">Graph.create_node</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.placeholder">
<code class="sig-name descname">placeholder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">name</span></em>, <em class="sig-param"><span class="n">type_expr</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.placeholder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.placeholder" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert a <code class="docutils literal notranslate"><span class="pre">placeholder</span></code> node into the Graph. A <code class="docutils literal notranslate"><span class="pre">placeholder</span></code> represents
a function input.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – A name for the input value. This corresponds to the name
of the positional argument to the function this <code class="docutils literal notranslate"><span class="pre">Graph</span></code> represents.</p></li>
<li><p><strong>type_expr</strong> (<em>Optional</em><em>[</em><em>Any</em><em>]</em>) – an optional type annotation representing the
Python type the output of this node will have. This is needed in some
cases for proper code generation (e.g. when the function is used
subsequently in TorchScript compilation).</p></li>
</ul>
</dd>
</dl>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The same insertion point and type expression rules apply for this method
as <code class="docutils literal notranslate"><span class="pre">Graph.create_node</span></code>.</p>
</div>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.print_tabular">
<code class="sig-name descname">print_tabular</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.print_tabular"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.print_tabular" title="Permalink to this definition">¶</a></dt>
<dd><p>Prints the intermediate representation of the graph in tabular
format.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Graph.python_code">
<code class="sig-name descname">python_code</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root_module</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/graph.html#Graph.python_code"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Graph.python_code" title="Permalink to this definition">¶</a></dt>
<dd><p>Turn this <code class="docutils literal notranslate"><span class="pre">Graph</span></code> into valid Python code.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>root_module</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The name of the root module on which to look-up
qualified name targets. This is usually ‘self’.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The string source code generated from this <code class="docutils literal notranslate"><span class="pre">Graph</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.fx.Node">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">Node</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">graph</span></em>, <em class="sig-param"><span class="n">name</span></em>, <em class="sig-param"><span class="n">op</span></em>, <em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em>, <em class="sig-param"><span class="n">type</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Node" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">Node</span></code> is the data structure that represents individual operations within
a <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. For the most part, Nodes represent callsites to various entities,
such as operators, methods, and Modules (some exceptions include nodes that
specify function inputs and outputs). Each <code class="docutils literal notranslate"><span class="pre">Node</span></code> has a function specified
by its <code class="docutils literal notranslate"><span class="pre">op</span></code> property. The <code class="docutils literal notranslate"><span class="pre">Node</span></code> semantics for each value of <code class="docutils literal notranslate"><span class="pre">op</span></code> are as follows:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">placeholder</span></code> represents a function input. The <code class="docutils literal notranslate"><span class="pre">name</span></code> attribute specifies the name this value will take on.
<code class="docutils literal notranslate"><span class="pre">target</span></code> is similarly the name of the argument. <code class="docutils literal notranslate"><span class="pre">args</span></code> holds either: 1) nothing, or 2) a single argument
denoting the default parameter of the function input. <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> is don’t-care. Placeholders correspond to
the function parameters (e.g. <code class="docutils literal notranslate"><span class="pre">x</span></code>) in the graph printout.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">get_attr</span></code> retrieves a parameter from the module hierarchy. <code class="docutils literal notranslate"><span class="pre">name</span></code> is similarly the name the result of the
fetch is assigned to. <code class="docutils literal notranslate"><span class="pre">target</span></code> is the fully-qualified name of the parameter’s position in the module hierarchy.
<code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> are don’t-care</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">call_function</span></code> applies a free function to some values. <code class="docutils literal notranslate"><span class="pre">name</span></code> is similarly the name of the value to assign
to. <code class="docutils literal notranslate"><span class="pre">target</span></code> is the function to be applied. <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> represent the arguments to the function,
following the Python calling convention</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">call_module</span></code> applies a module in the module hierarchy’s <code class="docutils literal notranslate"><span class="pre">forward()</span></code> method to given arguments. <code class="docutils literal notranslate"><span class="pre">name</span></code> is
as previous. <code class="docutils literal notranslate"><span class="pre">target</span></code> is the fully-qualified name of the module in the module hierarchy to call.
<code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> represent the arguments to invoke the module on, <em>including the self argument</em>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">call_method</span></code> calls a method on a value. <code class="docutils literal notranslate"><span class="pre">name</span></code> is as similar. <code class="docutils literal notranslate"><span class="pre">target</span></code> is the string name of the method
to apply to the <code class="docutils literal notranslate"><span class="pre">self</span></code> argument. <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> represent the arguments to invoke the module on,
<em>including the self argument</em></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">output</span></code> contains the output of the traced function in its <code class="docutils literal notranslate"><span class="pre">args[0]</span></code> attribute. This corresponds to the “return” statement
in the Graph printout.</p></li>
</ul>
<dl class="py method">
<dt id="torch.fx.Node.all_input_nodes">
<em class="property">property </em><code class="sig-name descname">all_input_nodes</code><a class="headerlink" href="#torch.fx.Node.all_input_nodes" title="Permalink to this definition">¶</a></dt>
<dd><p>Return all Nodes that are inputs to this Node. This is equivalent to
iterating over <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> and only collecting the values that
are Nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>List of <code class="docutils literal notranslate"><span class="pre">Nodes</span></code> that appear in the <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> of this
<code class="docutils literal notranslate"><span class="pre">Node</span></code>, in that order.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.append">
<code class="sig-name descname">append</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.append"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Node.append" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert x after this node in the list of nodes in the graph.
Equvalent to <code class="docutils literal notranslate"><span class="pre">self.next.prepend(x)</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The node to put after this node. Must be a member of the same graph.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.args">
<em class="property">property </em><code class="sig-name descname">args</code><a class="headerlink" href="#torch.fx.Node.args" title="Permalink to this definition">¶</a></dt>
<dd><p>The tuple of arguments to this <code class="docutils literal notranslate"><span class="pre">Node</span></code>. The interpretation of arguments
depends on the node’s opcode. See the <a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> docstring for more
information.</p>
<p>Assignment to this property is allowed. All accounting of uses and users
is updated automatically on assignment.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.kwargs">
<em class="property">property </em><code class="sig-name descname">kwargs</code><a class="headerlink" href="#torch.fx.Node.kwargs" title="Permalink to this definition">¶</a></dt>
<dd><p>The dict of keyword arguments to this <code class="docutils literal notranslate"><span class="pre">Node</span></code>. The interpretation of arguments
depends on the node’s opcode. See the <a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><code class="xref py py-class docutils literal notranslate"><span class="pre">Node</span></code></a> docstring for more
information.</p>
<p>Assignment to this property is allowed. All accounting of uses and users
is updated automatically on assignment.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.next">
<em class="property">property </em><code class="sig-name descname">next</code><a class="headerlink" href="#torch.fx.Node.next" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the next <code class="docutils literal notranslate"><span class="pre">Node</span></code> in the linked list of Nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The next <code class="docutils literal notranslate"><span class="pre">Node</span></code> in the linked list of Nodes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.prepend">
<code class="sig-name descname">prepend</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">x</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.prepend"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Node.prepend" title="Permalink to this definition">¶</a></dt>
<dd><p>Insert x before this node in the list of nodes in the graph. Example:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">Before</span><span class="p">:</span> <span class="n">p</span> <span class="o">-&gt;</span> <span class="bp">self</span>
        <span class="n">bx</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="n">ax</span>
<span class="n">After</span><span class="p">:</span>  <span class="n">p</span> <span class="o">-&gt;</span> <span class="n">x</span> <span class="o">-&gt;</span> <span class="bp">self</span>
        <span class="n">bx</span> <span class="o">-&gt;</span> <span class="n">ax</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>x</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The node to put before this node. Must be a member of the same graph.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.prev">
<em class="property">property </em><code class="sig-name descname">prev</code><a class="headerlink" href="#torch.fx.Node.prev" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the previous <code class="docutils literal notranslate"><span class="pre">Node</span></code> in the linked list of Nodes.</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>The previous <code class="docutils literal notranslate"><span class="pre">Node</span></code> in the linked list of Nodes.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Node.replace_all_uses_with">
<code class="sig-name descname">replace_all_uses_with</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">replace_with</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/node.html#Node.replace_all_uses_with"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Node.replace_all_uses_with" title="Permalink to this definition">¶</a></dt>
<dd><p>Replace all uses of <code class="docutils literal notranslate"><span class="pre">self</span></code> in the Graph with the Node <code class="docutils literal notranslate"><span class="pre">replace_with</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>replace_with</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The node to replace all uses of <code class="docutils literal notranslate"><span class="pre">self</span></code> with.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The list of Nodes on which this change was made.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.fx.Tracer">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">Tracer</code><span class="sig-paren">(</span><em class="sig-param">autowrap_modules=(&lt;module 'math' from '/opt/anaconda3/envs/pytorch/lib/python3.8/lib-dynload/math.cpython-38-darwin.so'&gt;</em>, <em class="sig-param">)</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">Tracer</span></code> is the class that implements the symbolic tracing functionality
of <code class="docutils literal notranslate"><span class="pre">torch.fx.symbolic_trace</span></code>. A call to <code class="docutils literal notranslate"><span class="pre">symbolic_trace(m)</span></code> is equivalent
to <code class="docutils literal notranslate"><span class="pre">Tracer().trace(m)</span></code>.</p>
<p>Tracer can be subclassed to override various behaviors of the tracing
process. The different behaviors that can be overridden are described
in the docstrings of the methods on this class.</p>
<dl class="py method">
<dt id="torch.fx.Tracer.call_module">
<code class="sig-name descname">call_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="n">forward</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer.call_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer.call_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Method that specifies the behavior of this <code class="docutils literal notranslate"><span class="pre">Tracer</span></code> when it encounters
a call to an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> instance.</p>
<p>By default, the behavior is to check if the called module is a leaf module
via <code class="docutils literal notranslate"><span class="pre">is_leaf_module</span></code>. If it is, emit a <code class="docutils literal notranslate"><span class="pre">call_module</span></code> node referring to
<code class="docutils literal notranslate"><span class="pre">m</span></code> in the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>. Otherwise, call the <code class="docutils literal notranslate"><span class="pre">Module</span></code> normally, tracing through
the operations in its <code class="docutils literal notranslate"><span class="pre">forward</span></code> function.</p>
<p>This method can be overridden to–for example–create nested traced
GraphModules, or any other behavior you would want while tracing across
<code class="docutils literal notranslate"><span class="pre">Module</span></code> boundaries.
<code class="docutils literal notranslate"><span class="pre">Module</span></code> boundaries.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<a class="reference internal" href="generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – The module for which a call is being emitted</p></li>
<li><p><strong>forward</strong> (<em>Callable</em>) – The forward() method of the <code class="docutils literal notranslate"><span class="pre">Module</span></code> to be invoked</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – args of the module callsite</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – kwargs of the module callsite</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The return value from the Module call. In the case that a <code class="docutils literal notranslate"><span class="pre">call_module</span></code>
node was emitted, this is a <code class="docutils literal notranslate"><span class="pre">Proxy</span></code> value. Otherwise, it is whatever
value was returned from the <code class="docutils literal notranslate"><span class="pre">Module</span></code> invocation.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Tracer.create_arg">
<code class="sig-name descname">create_arg</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">a</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer.create_arg"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer.create_arg" title="Permalink to this definition">¶</a></dt>
<dd><p>A method to specify the behavior of tracing when preparing values to
be used as arguments to nodes in the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>.</p>
<p>By default, the behavior includes:</p>
<ol class="arabic">
<li><p>Iterate through collection types (e.g. tuple, list, dict) and recursively
call <code class="docutils literal notranslate"><span class="pre">create_args</span></code> on the elements.</p></li>
<li><p>Given a Proxy object, return a reference to the underlying IR <code class="docutils literal notranslate"><span class="pre">Node</span></code></p></li>
<li><p>Given a non-Proxy Tensor object, emit IR for various cases:</p>
<blockquote>
<div><ul class="simple">
<li><p>For a Parameter, emit a <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> node referring to that Parameter</p></li>
<li><p>For a non-Parameter Tensor, store the Tensor away in a special
attribute referring to that attribute.</p></li>
</ul>
</div></blockquote>
</li>
</ol>
<p>This method can be overridden to support more types.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>a</strong> (<em>Any</em>) – The value to be emitted as an <code class="docutils literal notranslate"><span class="pre">Argument</span></code> in the <code class="docutils literal notranslate"><span class="pre">Graph</span></code>.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The value <code class="docutils literal notranslate"><span class="pre">a</span></code> converted into the appropriate <code class="docutils literal notranslate"><span class="pre">Argument</span></code></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Tracer.create_args_for_root">
<code class="sig-name descname">create_args_for_root</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root_fn</span></em>, <em class="sig-param"><span class="n">is_module</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer.create_args_for_root"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer.create_args_for_root" title="Permalink to this definition">¶</a></dt>
<dd><p>Create <code class="docutils literal notranslate"><span class="pre">placeholder</span></code> nodes corresponding to the signature of the <code class="docutils literal notranslate"><span class="pre">root</span></code>
Module. This method introspects root’s signature and emits those
nodes accordingly, also supporting <code class="docutils literal notranslate"><span class="pre">*args</span></code> and <code class="docutils literal notranslate"><span class="pre">**kwargs</span></code>.</p>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Tracer.is_leaf_module">
<code class="sig-name descname">is_leaf_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">m</span></em>, <em class="sig-param"><span class="n">module_qualified_name</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer.is_leaf_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer.is_leaf_module" title="Permalink to this definition">¶</a></dt>
<dd><p>A method to specify whether a given <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> is a “leaf” module.</p>
<p>Leaf modules are the atomic units that appear in
the IR, referenced by <code class="docutils literal notranslate"><span class="pre">call_module</span></code> calls. By default,
Modules in the PyTorch standard library namespace (torch.nn)
are leaf modules. All other modules are traced through and
their constituent ops are recorded, unless specified otherwise
via this parameter.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>m</strong> (<a class="reference internal" href="generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a>) – The module being queried about</p></li>
<li><p><strong>module_qualified_name</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The path to root of this module. For example,
if you have a module hierarchy where submodule <code class="docutils literal notranslate"><span class="pre">foo</span></code> contains
submodule <code class="docutils literal notranslate"><span class="pre">bar</span></code>, which contains submodule <code class="docutils literal notranslate"><span class="pre">baz</span></code>, that module will
appear with the qualified name <code class="docutils literal notranslate"><span class="pre">foo.bar.baz</span></code> here.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Tracer.path_of_module">
<code class="sig-name descname">path_of_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">mod</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer.path_of_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer.path_of_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Helper method to find the qualified name of <code class="docutils literal notranslate"><span class="pre">mod</span></code> in the Module hierarchy
of <code class="docutils literal notranslate"><span class="pre">root</span></code>. For example, if <code class="docutils literal notranslate"><span class="pre">root</span></code> has a submodule named <code class="docutils literal notranslate"><span class="pre">foo</span></code>, which has
a submodule named <code class="docutils literal notranslate"><span class="pre">bar</span></code>, passing <code class="docutils literal notranslate"><span class="pre">bar</span></code> into this function will return
the string “foo.bar”.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>mod</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The <code class="docutils literal notranslate"><span class="pre">Module</span></code> to retrieve the qualified name for.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Tracer.trace">
<code class="sig-name descname">trace</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">root</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/symbolic_trace.html#Tracer.trace"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Tracer.trace" title="Permalink to this definition">¶</a></dt>
<dd><p>Trace <code class="docutils literal notranslate"><span class="pre">root</span></code> and return the corresponding FX <code class="docutils literal notranslate"><span class="pre">Graph</span></code> representation. <code class="docutils literal notranslate"><span class="pre">root</span></code>
can either be an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> instance or a Python callable.</p>
<p>Note that after this call, <code class="docutils literal notranslate"><span class="pre">self.root</span></code> may be different from the <code class="docutils literal notranslate"><span class="pre">root</span></code> passed
in here. For example, when a free function is passed to <code class="docutils literal notranslate"><span class="pre">trace()</span></code>, we will
create an <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> instance to use as the root and add embedded constants
to.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>root</strong> (<em>Union</em><em>[</em><a class="reference internal" href="generated/torch.nn.Module.html#torch.nn.Module" title="torch.nn.Module"><em>Module</em></a><em>, </em><em>Callable</em><em>]</em>) – Either a <code class="docutils literal notranslate"><span class="pre">Module</span></code> or a function to be
traced through.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>A <code class="docutils literal notranslate"><span class="pre">Graph</span></code> representing the semantics of the passed-in <code class="docutils literal notranslate"><span class="pre">root</span></code>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.fx.Proxy">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">Proxy</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">node</span></em>, <em class="sig-param"><span class="n">tracer</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/proxy.html#Proxy"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Proxy" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">Proxy</span></code> objects are <code class="docutils literal notranslate"><span class="pre">Node</span></code> wrappers that flow through the
program during symbolic tracing and record all the operations
(<code class="docutils literal notranslate"><span class="pre">torch</span></code> function calls, method calls, operators) that they touch
into the growing FX Graph.</p>
<p>If you’re doing graph transforms, you can wrap your own <code class="docutils literal notranslate"><span class="pre">Proxy</span></code>
method around a raw <code class="docutils literal notranslate"><span class="pre">Node</span></code> so that you can use the overloaded
operators to add additional things to a <code class="docutils literal notranslate"><span class="pre">Graph</span></code>.</p>
</dd></dl>

<dl class="py class">
<dt id="torch.fx.Interpreter">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">Interpreter</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter" title="Permalink to this definition">¶</a></dt>
<dd><p>An Interpreter executes an FX graph Node-by-Node. This pattern
can be useful for many things, including writing code
transformations as well as analysis passes.</p>
<p>Methods in the Interpreter class can be overridden to customize
the behavior of execution. The map of overrideable methods
in terms of call hierarchy:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">run</span><span class="p">()</span>
    <span class="o">+--</span> <span class="n">run_node</span>
        <span class="o">+--</span> <span class="n">placeholder</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">get_attr</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">call_function</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">call_method</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">call_module</span><span class="p">()</span>
        <span class="o">+--</span> <span class="n">output</span><span class="p">()</span>
</pre></div>
</div>
<p class="rubric">Example</p>
<p>Suppose we want to swap all instances of <code class="docutils literal notranslate"><span class="pre">torch.neg</span></code> with
<code class="docutils literal notranslate"><span class="pre">torch.sigmoid</span></code> and vice versa (including their <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>
method equivalents). We could subclass Interpreter like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NegSigmSwapInterpreter</span><span class="p">(</span><span class="n">Interpreter</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span> <span class="p">:</span> <span class="n">Target</span><span class="p">,</span>
                      <span class="n">args</span> <span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">kwargs</span> <span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call_method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span> <span class="p">:</span> <span class="n">Target</span><span class="p">,</span>
                    <span class="n">args</span> <span class="p">:</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">kwargs</span> <span class="p">:</span> <span class="n">Dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s1">&#39;neg&#39;</span><span class="p">:</span>
            <span class="n">call_self</span><span class="p">,</span> <span class="o">*</span><span class="n">args_tail</span> <span class="o">=</span> <span class="n">args</span>
            <span class="k">return</span> <span class="n">call_self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">*</span><span class="n">args_tail</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_method</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>

<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">NegSigmSwapInterpreter</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> (<a class="reference internal" href="#torch.fx.GraphModule" title="torch.fx.GraphModule"><em>GraphModule</em></a>) – The module to be executed</p>
</dd>
</dl>
<dl class="py method">
<dt id="torch.fx.Interpreter.call_function">
<code class="sig-name descname">call_function</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.call_function"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.call_function" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">call_function</span></code> node and return the result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Return</dt><dd><p>Any: The value returned by the function invocation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.call_method">
<code class="sig-name descname">call_method</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.call_method"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.call_method" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">call_method</span></code> node and return the result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Return</dt><dd><p>Any: The value returned by the method invocation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.call_module">
<code class="sig-name descname">call_module</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.call_module"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.call_module" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">call_module</span></code> node and return the result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Return</dt><dd><p>Any: The value returned by the module invocation</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.fetch_args_kwargs_from_env">
<code class="sig-name descname">fetch_args_kwargs_from_env</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.fetch_args_kwargs_from_env"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.fetch_args_kwargs_from_env" title="Permalink to this definition">¶</a></dt>
<dd><p>Fetch the concrete values of <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> of node <code class="docutils literal notranslate"><span class="pre">n</span></code>
from the current execution environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The node for which <code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> should be fetched.</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p><code class="docutils literal notranslate"><span class="pre">args</span></code> and <code class="docutils literal notranslate"><span class="pre">kwargs</span></code> with concrete values for <code class="docutils literal notranslate"><span class="pre">n</span></code>.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Tuple[Tuple, Dict]</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.fetch_attr">
<code class="sig-name descname">fetch_attr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.fetch_attr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.fetch_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Fetch an attribute from the <code class="docutils literal notranslate"><span class="pre">Module</span></code> hierarchy of <code class="docutils literal notranslate"><span class="pre">self.module</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>target</strong> (<a class="reference external" href="https://docs.python.org/3/library/stdtypes.html#str" title="(in Python v3.9)"><em>str</em></a>) – The fully-qualfiied name of the attribute to fetch</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The value of the attribute.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.get_attr">
<code class="sig-name descname">get_attr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.get_attr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.get_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> node. Will retrieve an attribute
value from the <code class="docutils literal notranslate"><span class="pre">Module</span></code> hierarchy of <code class="docutils literal notranslate"><span class="pre">self.module</span></code>.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The value of the attribute that was retrieved</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.map_nodes_to_values">
<code class="sig-name descname">map_nodes_to_values</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.map_nodes_to_values"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.map_nodes_to_values" title="Permalink to this definition">¶</a></dt>
<dd><p>Recursively descend through <code class="docutils literal notranslate"><span class="pre">args</span></code> and look up the concrete value
for each <code class="docutils literal notranslate"><span class="pre">Node</span></code> in the current execution environment.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>args</strong> (<em>Argument</em>) – Data structure within which to look up concrete values</p></li>
<li><p><strong>n</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – Node to which <code class="docutils literal notranslate"><span class="pre">args</span></code> belongs. This is only used for error reporting.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.output">
<code class="sig-name descname">output</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.output"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.output" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute an <code class="docutils literal notranslate"><span class="pre">output</span></code> node. This really just retrieves
the value referenced by the <code class="docutils literal notranslate"><span class="pre">output</span></code> node and returns it.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The return value referenced by the output node</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.placeholder">
<code class="sig-name descname">placeholder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.placeholder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.placeholder" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">placeholder</span></code> node. Note that this is stateful:
<code class="docutils literal notranslate"><span class="pre">Interpreter</span></code> maintains an internal iterator over
arguments passed to <code class="docutils literal notranslate"><span class="pre">run</span></code> and this method returns
next() on that iterator.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The argument value that was retrieved.</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.run">
<code class="sig-name descname">run</code><span class="sig-paren">(</span><em class="sig-param"><span class="o">*</span><span class="n">args</span></em>, <em class="sig-param"><span class="n">initial_env</span><span class="o">=</span><span class="default_value">None</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.run"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.run" title="Permalink to this definition">¶</a></dt>
<dd><p>Run <cite>module</cite> via interpretation and return the result.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>*args</strong> – The arguments to the Module to run, in positional order</p></li>
<li><p><strong>initial_env</strong> (<em>Optional</em><em>[</em><em>Dict</em><em>[</em><a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a><em>, </em><em>Any</em><em>]</em><em>]</em>) – An optional starting environment for execution.
This is a dict mapping <cite>Node</cite> to any value. This can be used, for example, to
pre-populate results for certain <cite>Nodes</cite> so as to do only partial evaluation within
the interpreter.</p></li>
</ul>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The value returned from executing the Module</p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Interpreter.run_node">
<code class="sig-name descname">run_node</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">n</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Interpreter.run_node"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Interpreter.run_node" title="Permalink to this definition">¶</a></dt>
<dd><p>Run a specific node <code class="docutils literal notranslate"><span class="pre">n</span></code> and return the result.
Calls into placeholder, get_attr, call_function,
call_method, call_module, or output depending
on <code class="docutils literal notranslate"><span class="pre">node.op</span></code></p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>n</strong> (<a class="reference internal" href="#torch.fx.Node" title="torch.fx.Node"><em>Node</em></a>) – The Node to execute</p>
</dd>
<dt class="field-even">Returns</dt>
<dd class="field-even"><p>The result of executing <code class="docutils literal notranslate"><span class="pre">n</span></code></p>
</dd>
<dt class="field-odd">Return type</dt>
<dd class="field-odd"><p>Any</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt id="torch.fx.Transformer">
<em class="property">class </em><code class="sig-prename descclassname">torch.fx.</code><code class="sig-name descname">Transformer</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">module</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Transformer" title="Permalink to this definition">¶</a></dt>
<dd><p><code class="docutils literal notranslate"><span class="pre">Transformer</span></code> is a special type of interpreter that produces a
new <code class="docutils literal notranslate"><span class="pre">Module</span></code>. It exposes a <code class="docutils literal notranslate"><span class="pre">transform()</span></code> method that returns
the transformed <code class="docutils literal notranslate"><span class="pre">Module</span></code>. <code class="docutils literal notranslate"><span class="pre">Transformer</span></code> does not require
arguments to run, as <code class="docutils literal notranslate"><span class="pre">Interpreter</span></code> does. <code class="docutils literal notranslate"><span class="pre">Transformer</span></code> works
entirely symbolically.</p>
<p class="rubric">Example</p>
<p>Suppose we want to swap all instances of <code class="docutils literal notranslate"><span class="pre">torch.neg</span></code> with
<code class="docutils literal notranslate"><span class="pre">torch.sigmoid</span></code> and vice versa (including their <code class="docutils literal notranslate"><span class="pre">Tensor</span></code>
method equivalents). We could subclass <code class="docutils literal notranslate"><span class="pre">Transformer</span></code> like so:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">NegSigmSwapXformer</span><span class="p">(</span><span class="n">Transformer</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">call_function</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span> <span class="p">:</span> <span class="s1">&#39;Target&#39;</span><span class="p">,</span> <span class="n">args</span> <span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">kwargs</span> <span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">:</span>
            <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_function</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">call_method</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">target</span> <span class="p">:</span> <span class="s1">&#39;Target&#39;</span><span class="p">,</span> <span class="n">args</span> <span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">],</span> <span class="n">kwargs</span> <span class="p">:</span> <span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Any</span><span class="p">])</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">target</span> <span class="o">==</span> <span class="s1">&#39;neg&#39;</span><span class="p">:</span>
            <span class="n">call_self</span><span class="p">,</span> <span class="o">*</span><span class="n">args_tail</span> <span class="o">=</span> <span class="n">args</span>
            <span class="k">return</span> <span class="n">call_self</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="o">*</span><span class="n">args_tail</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="k">return</span> <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="n">call_method</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">fn</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span><span class="o">.</span><span class="n">neg</span><span class="p">()</span>

<span class="n">gm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">fx</span><span class="o">.</span><span class="n">symbolic_trace</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>

<span class="n">transformed</span> <span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span> <span class="o">=</span> <span class="n">NegSigmSwapXformer</span><span class="p">(</span><span class="n">gm</span><span class="p">)</span><span class="o">.</span><span class="n">transform</span><span class="p">()</span>
<span class="nb">input</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">testing</span><span class="o">.</span><span class="n">assert_allclose</span><span class="p">(</span><span class="n">transformed</span><span class="p">(</span><span class="nb">input</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">neg</span><span class="p">(</span><span class="nb">input</span><span class="p">)</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">())</span>
</pre></div>
</div>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>module</strong> (<a class="reference internal" href="#torch.fx.GraphModule" title="torch.fx.GraphModule"><em>GraphModule</em></a>) – The <code class="docutils literal notranslate"><span class="pre">Module</span></code> to be transformed.</p>
</dd>
</dl>
<dl class="py method">
<dt id="torch.fx.Transformer.get_attr">
<code class="sig-name descname">get_attr</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.get_attr"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Transformer.get_attr" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> node. In <code class="docutils literal notranslate"><span class="pre">Transformer</span></code>, this is
overridden to insert a new <code class="docutils literal notranslate"><span class="pre">get_attr</span></code> node into the output
graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Transformer.placeholder">
<code class="sig-name descname">placeholder</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">target</span></em>, <em class="sig-param"><span class="n">args</span></em>, <em class="sig-param"><span class="n">kwargs</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.placeholder"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Transformer.placeholder" title="Permalink to this definition">¶</a></dt>
<dd><p>Execute a <code class="docutils literal notranslate"><span class="pre">placeholder</span></code> node. In <code class="docutils literal notranslate"><span class="pre">Transformer</span></code>, this is
overridden to insert a new <code class="docutils literal notranslate"><span class="pre">placeholder</span></code> into the output
graph.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>target</strong> (<em>Target</em>) – The call target for this node. See
<a class="reference external" href="https://pytorch.org/docs/master/fx.html#torch.fx.Node">Node</a> for
details on semantics</p></li>
<li><p><strong>args</strong> (<em>Tuple</em>) – Tuple of positional args for this invocation</p></li>
<li><p><strong>kwargs</strong> (<em>Dict</em>) – Dict of keyword arguments for this invocation</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt id="torch.fx.Transformer.transform">
<code class="sig-name descname">transform</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/torch/fx/interpreter.html#Transformer.transform"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#torch.fx.Transformer.transform" title="Permalink to this definition">¶</a></dt>
<dd><p>Transform <code class="docutils literal notranslate"><span class="pre">self.module</span></code> and return the transformed
<code class="docutils literal notranslate"><span class="pre">GraphModule</span></code>.</p>
</dd></dl>

</dd></dl>

</div>
</div>


             </article>
             
            </div>
            <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="hub.html" class="btn btn-neutral float-right" title="torch.hub" accesskey="n" rel="next">Next <img src="_static/images/chevron-right-orange.svg" class="next-page"></a>
      
      
        <a href="futures.html" class="btn btn-neutral" title="torch.futures" accesskey="p" rel="prev"><img src="_static/images/chevron-right-orange.svg" class="previous-page"> Previous</a>
      
    </div>
  

  

    <hr>

  

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, Torch Contributors.

    </p>
  </div>
    
      <div>
        Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>.
      </div>
     

</footer>

          </div>
        </div>

        <div class="pytorch-content-right" id="pytorch-content-right">
          <div class="pytorch-right-menu" id="pytorch-right-menu">
            <div class="pytorch-side-scroll" id="pytorch-side-scroll-right">
              <ul>
<li><a class="reference internal" href="#">torch.fx</a><ul>
<li><a class="reference internal" href="#module-torch.fx">Overview</a></li>
<li><a class="reference internal" href="#writing-transformations">Writing Transformations</a></li>
<li><a class="reference internal" href="#debugging-transformations">Debugging Transformations</a></li>
<li><a class="reference internal" href="#limitations-of-symbolic-tracing">Limitations of Symbolic Tracing</a><ul>
<li><a class="reference internal" href="#dynamic-control-flow">Dynamic Control Flow</a><ul>
<li><a class="reference internal" href="#static-control-flow">Static Control Flow</a></li>
</ul>
</li>
<li><a class="reference internal" href="#non-torch-functions">Non-<code class="docutils literal notranslate"><span class="pre">torch</span></code> Functions</a></li>
<li><a class="reference internal" href="#customizing-tracing-with-the-tracer-class">Customizing Tracing with the <code class="docutils literal notranslate"><span class="pre">Tracer</span></code> class</a><ul>
<li><a class="reference internal" href="#leaf-modules">Leaf Modules</a></li>
</ul>
</li>
<li><a class="reference internal" href="#miscellanea">Miscellanea</a></li>
</ul>
</li>
<li><a class="reference internal" href="#api-reference">API Reference</a></li>
</ul>
</li>
</ul>

            </div>
          </div>
        </div>
      </section>
    </div>

  


  

     
       <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
         <script src="_static/jquery.js"></script>
         <script src="_static/underscore.js"></script>
         <script src="_static/doctools.js"></script>
         <script src="_static/language_data.js"></script>
     

  

  <script type="text/javascript" src="_static/js/vendor/popper.min.js"></script>
  <script type="text/javascript" src="_static/js/vendor/bootstrap.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/list.js/1.5.0/list.min.js"></script>
  <script type="text/javascript" src="_static/js/theme.js"></script>

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>
 
<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
  (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
  m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

  ga('create', 'UA-90545585-1', 'auto');
  ga('send', 'pageview');

</script>

<script async src="https://www.googletagmanager.com/gtag/js?id=UA-117752657-2"></script>

<script>
  window.dataLayer = window.dataLayer || [];

  function gtag(){dataLayer.push(arguments);}

  gtag('js', new Date());
  gtag('config', 'UA-117752657-2');
</script>

<img height="1" width="1" style="border-style:none;" alt="" src="https://www.googleadservices.com/pagead/conversion/795629140/?label=txkmCPmdtosBENSssfsC&amp;guid=ON&amp;script=0"/>


  <!-- Begin Footer -->

  <div class="container-fluid docs-tutorials-resources" id="docs-tutorials-resources">
    <div class="container">
      <div class="row">
        <div class="col-md-4 text-center">
          <h2>Docs</h2>
          <p>Access comprehensive developer documentation for PyTorch</p>
          <a class="with-right-arrow" href="https://pytorch.org/docs/stable/index.html">View Docs</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Tutorials</h2>
          <p>Get in-depth tutorials for beginners and advanced developers</p>
          <a class="with-right-arrow" href="https://pytorch.org/tutorials">View Tutorials</a>
        </div>

        <div class="col-md-4 text-center">
          <h2>Resources</h2>
          <p>Find development resources and get your questions answered</p>
          <a class="with-right-arrow" href="https://pytorch.org/resources">View Resources</a>
        </div>
      </div>
    </div>
  </div>

  <footer class="site-footer">
    <div class="container footer-container">
      <div class="footer-logo-wrapper">
        <a href="https://pytorch.org/" class="footer-logo"></a>
      </div>

      <div class="footer-links-wrapper">
        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/">PyTorch</a></li>
            <li><a href="https://pytorch.org/get-started">Get Started</a></li>
            <li><a href="https://pytorch.org/features">Features</a></li>
            <li><a href="https://pytorch.org/ecosystem">Ecosystem</a></li>
            <li><a href="https://pytorch.org/blog/">Blog</a></li>
            <li><a href="https://github.com/pytorch/pytorch/blob/master/CONTRIBUTING.md">Contributing</a></li>
          </ul>
        </div>

        <div class="footer-links-col">
          <ul>
            <li class="list-title"><a href="https://pytorch.org/resources">Resources</a></li>
            <li><a href="https://pytorch.org/tutorials">Tutorials</a></li>
            <li><a href="https://pytorch.org/docs/stable/index.html">Docs</a></li>
            <li><a href="https://discuss.pytorch.org" target="_blank">Discuss</a></li>
            <li><a href="https://github.com/pytorch/pytorch/issues" target="_blank">Github Issues</a></li>
            <li><a href="https://pytorch.org/assets/brand-guidelines/PyTorch-Brand-Guidelines.pdf" target="_blank">Brand Guidelines</a></li>
          </ul>
        </div>

        <div class="footer-links-col follow-us-col">
          <ul>
            <li class="list-title">Stay Connected</li>
            <li>
              <div id="mc_embed_signup">
                <form
                  action="https://twitter.us14.list-manage.com/subscribe/post?u=75419c71fe0a935e53dfa4a3f&id=91d0dccd39"
                  method="post"
                  id="mc-embedded-subscribe-form"
                  name="mc-embedded-subscribe-form"
                  class="email-subscribe-form validate"
                  target="_blank"
                  novalidate>
                  <div id="mc_embed_signup_scroll" class="email-subscribe-form-fields-wrapper">
                    <div class="mc-field-group">
                      <label for="mce-EMAIL" style="display:none;">Email Address</label>
                      <input type="email" value="" name="EMAIL" class="required email" id="mce-EMAIL" placeholder="Email Address">
                    </div>

                    <div id="mce-responses" class="clear">
                      <div class="response" id="mce-error-response" style="display:none"></div>
                      <div class="response" id="mce-success-response" style="display:none"></div>
                    </div>    <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->

                    <div style="position: absolute; left: -5000px;" aria-hidden="true"><input type="text" name="b_75419c71fe0a935e53dfa4a3f_91d0dccd39" tabindex="-1" value=""></div>

                    <div class="clear">
                      <input type="submit" value="" name="subscribe" id="mc-embedded-subscribe" class="button email-subscribe-button">
                    </div>
                  </div>
                </form>
              </div>

            </li>
          </ul>

          <div class="footer-social-icons">
            <a href="https://www.facebook.com/pytorch" target="_blank" class="facebook"></a>
            <a href="https://twitter.com/pytorch" target="_blank" class="twitter"></a>
            <a href="https://www.youtube.com/pytorch" target="_blank" class="youtube"></a>
          </div>
        </div>
      </div>
    </div>
  </footer>

  <div class="cookie-banner-wrapper">
  <div class="container">
    <p class="gdpr-notice">To analyze traffic and optimize your experience, we serve cookies on this site. By clicking or navigating, you agree to allow our usage of cookies. As the current maintainers of this site, Facebook’s Cookies Policy applies. Learn more, including about available controls: <a href="https://www.facebook.com/policies/cookies/">Cookies Policy</a>.</p>
    <img class="close-button" src="_static/images/pytorch-x.svg">
  </div>
</div>

  <!-- End Footer -->

  <!-- Begin Mobile Menu -->

  <div class="mobile-main-menu">
    <div class="container-fluid">
      <div class="container">
        <div class="mobile-main-menu-header-container">
          <a class="header-logo" href="https://pytorch.org/" aria-label="PyTorch"></a>
          <a class="main-menu-close-button" href="#" data-behavior="close-mobile-menu"></a>
        </div>
      </div>
    </div>

    <div class="mobile-main-menu-links-container">
      <div class="main-menu">
        <ul>
          <li>
            <a href="https://pytorch.org/get-started">Get Started</a>
          </li>

          <li>
            <a href="https://pytorch.org/ecosystem">Ecosystem</a>
          </li>

          <li>
            <a href="https://pytorch.org/mobile">Mobile</a>
          </li>

          <li>
            <a href="https://pytorch.org/hub">PyTorch Hub</a>
          </li>

          <li>
            <a href="https://pytorch.org/blog/">Blog</a>
          </li>

          <li>
            <a href="https://pytorch.org/tutorials">Tutorials</a>
          </li>

          <li class="resources-mobile-menu-title" class="active">
            Docs
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/docs/stable/index.html">PyTorch</a>
            </li>

            <li>
              <a href="https://pytorch.org/audio/stable/index.html">torchaudio</a>
            </li>

            <li>
              <a href="https://pytorch.org/text/stable/index.html">torchtext</a>
            </li>

            <li>
              <a href="https://pytorch.org/docs/stable/torchvision/">torchvision</a>
            </li>

            <li>
              <a href="https://pytorch.org/elastic/">TorchElastic</a>
            </li>

            <li>
              <a href="https://pytorch.org/serve/">TorchServe</a>
            </li>

            <li>
              <a href="https://pytorch.org/xla">PyTorch on XLA Devices</a>
            </li>
          </ul>

          <li class="resources-mobile-menu-title">
            Resources
          </li>

          <ul class="resources-mobile-menu-items">
            <li>
              <a href="https://pytorch.org/resources">Developer Resources</a>
            </li>

            <li>
              <a href="https://pytorch.org/features">About</a>
            </li>

            <li>
              <a href="https://pytorch.org/hub">Models (Beta)</a>
            </li>

            <li>
              <a href="https://pytorch.org/#community-module">Community</a>
            </li>

            <li>
              <a href="https://discuss.pytorch.org/">Forums</a>
            </li>
          </ul>

          <li>
            <a href="https://github.com/pytorch/pytorch">Github</a>
          </li>
        </ul>
      </div>
    </div>
  </div>

  <!-- End Mobile Menu -->

  <script type="text/javascript" src="_static/js/vendor/anchor.min.js"></script>

  <script type="text/javascript">
    $(document).ready(function() {
      mobileMenu.bind();
      mobileTOC.bind();
      pytorchAnchors.bind();
      sideMenus.bind();
      scrollToAnchor.bind();
      highlightNavigation.bind();
      mainMenuDropdown.bind();
      filterTags.bind();

      // Add class to links that have code blocks, since we cannot create links in code blocks
      $("article.pytorch-article a span.pre").each(function(e) {
        $(this).closest("a").addClass("has-code");
      });
    })
  </script>
</body>
</html>